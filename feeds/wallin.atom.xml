<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jonas Wallin, mathematical statistics</title><link href="/" rel="alternate"></link><link href="/feeds/wallin.atom.xml" rel="self"></link><id>/</id><updated>2015-05-14T00:00:00+02:00</updated><entry><title>BayesFlow Latent modeling of flow cytometry cell populations</title><link href="/articles/2015/05/bayesflow-latent-modeling-of-flow-cytometry-cell-populations/" rel="alternate"></link><updated>2015-05-14T00:00:00+02:00</updated><author><name>Wallin</name></author><id>tag:,2015-05-14:articles/2015/05/bayesflow-latent-modeling-of-flow-cytometry-cell-populations/</id><summary type="html">&lt;p&gt;Here we formulate a Bayesian hierarchical model, that models the variation across indivuals for 
clow cytometry data. The cell data is follows a Gaussian mixture model, wheras the mean and covariance of each class--representing a certain cell type-- is joint in a latent layer.
Sampling of the posterior distribution is done through a Gibbs sampler, 
where the sampling is parallelised across indivuals.
All (python) code is available at available  &lt;a href="https://github.com/JonasWallin/BayesFlow"&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Extensions:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Lots on the way&lt;/li&gt;
&lt;/ul&gt;</summary><category term="article"></category><category term="MCMC"></category><category term="GMM"></category><category term="flow_cytometry"></category><category term="Hierarchical"></category><category term="mixture"></category></entry><entry><title>LGFM model</title><link href="/articles/2014/03/lgfm-model/" rel="alternate"></link><updated>2014-03-25T00:00:00+01:00</updated><author><name>Bolin</name></author><id>tag:,2014-03-25:articles/2014/03/lgfm-model/</id><summary type="html">&lt;p&gt;We introduce the the latent Gaussian random field mixture (LGFM) models.
The model class combines the discrete Markov random fields (MRFs) with latent Gaussian random field models and can be used for simultaneous segmentation, noise reduction, and interpolation of spatial data. The latent model is defined as a mixture of several, possibly multivariate, Gaussian random fields, and which of the fields that is observed at each location is modeled using a discrete random field, such as a discrete MRF.&lt;/p&gt;
&lt;p&gt;As an application we study the noise reduction ability on a magnetic resonance imaging data. In a simulation study (not in the preprint) we also study the ability to detect discontinouties in mean functions of latent Gaussian process. The model preforms much better then the regular latent Gaussian model in recustring the latent fields in both the simulation study and in the noise reduction of the real data. &lt;/p&gt;</summary><category term="MRF model"></category><category term="latent Gaussian process"></category><category term="estimation"></category><category term="kriging"></category><category term="mri imaging"></category></entry><entry><title>Slepian models for LMA</title><link href="/articles/2014/03/slepian-models-for-lma/" rel="alternate"></link><updated>2014-03-25T00:00:00+01:00</updated><author><name>Podg√≥rski</name></author><id>tag:,2014-03-25:articles/2014/03/slepian-models-for-lma/</id><summary type="html">&lt;p&gt;The article describes the concept of Slepian noise. A slepian models describes the behavior of a stochastic process (in time) crossing a certain level, $u$. The main contribution of the articles are method to simulate slepian for Laplace moving average models. That is models of the type 
$$
 X(t) = \int f(t-s) d\Lambda(s),
$$
where $\Lambda(s)$ is Laplace moving average. &lt;/p&gt;
&lt;p&gt;We compare the Slepian Laplace model to the regular Gaussian version on data that micis cars driving on roads. The figure displays the upcrossing of the accelaration of a person given that drives on a Laplace moving average road. 
R ana matlab code for the Laplace crossing&lt;/p&gt;</summary><category term="Laplace moving average"></category><category term="Slepian"></category><category term="stochastic process"></category><category term="upcrossing"></category></entry><entry><title>non-Gaussian Matern Fields</title><link href="/articles/2013/07/non-gaussian-matern-fields/" rel="alternate"></link><updated>2013-07-24T00:00:00+02:00</updated><author><name>Bolin</name></author><id>tag:,2013-07-24:articles/2013/07/non-gaussian-matern-fields/</id><summary type="html">&lt;p&gt;In this article, we exaim how to preform estimation and predicition on a certain type of continous non Gaussian random fields models.
The article is an application extension of the article &lt;a href="http://arxiv.org/abs/1206.0622"&gt;Bolin 2013&lt;/a&gt; (now published in SJS).
We extend the models in the article, by adding measurement noise and covariates; the estimation
is done through a MCEM algorithm. 
We also test how the models preform on a real data set with precipitation over the US; comparing the model to the
standard Gaussian and transformed Gaussian models. The conlusion for this data is that the models works well
but we need to incorporate covariates into the variance, since the mean and variance of the data is clearly linked.&lt;/p&gt;
&lt;p&gt;R code is available at: &lt;a href="https://bitbucket.org/davidbolin/lang"&gt;Lang&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Extensions:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The next planned extension is to change from MCEM to other stochastic estimation methods; There are two main reasons
    for this, first hopefully we can improve the speed of the algorithm, secondly we hope it allowes for more advanced models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Expanding the model for regular grids; where a more rich noise class can be studied.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="article"></category><category term="generalized Hyperbolic disribution"></category><category term="MCEM"></category><category term="SPDEs"></category><category term="spatial"></category><category term="precipitation"></category></entry><entry><title>Convolution of Generalized Hyperbolic</title><link href="/articles/2013/06/convolution-of-generalized-hyperbolic/" rel="alternate"></link><updated>2013-06-15T00:00:00+02:00</updated><author><name>Podgorski</name></author><id>tag:,2013-06-15:articles/2013/06/convolution-of-generalized-hyperbolic/</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;In this article, we show that the only sub distributions of &lt;a href="http://en.wikipedia.org/wiki/Generalised_hyperbolic_distribution"&gt;the Generalized hyperbolic distribution&lt;/a&gt; that are closed under convolution are &lt;a href="http://en.wikipedia.org/wiki/Normal-inverse_Gaussian_distribution"&gt;the Normal Inverse Gaussian distribution (NIG)&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Variance-gamma_distribution"&gt;the Generalized Laplace distribution (GAL)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The results are derived through showing that &lt;a href="http://en.wikipedia.org/wiki/Gamma_distribution"&gt;the Gamma distribution&lt;/a&gt; and the &lt;a href="http://en.wikipedia.org/wiki/Inverse_Gaussian_distribution"&gt;Inverse Gaussian distribution&lt;/a&gt; are the only sub distributions of &lt;a href="http://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution"&gt;the Generalized inverse Gaussian distribution&lt;/a&gt; that are closed under distribution.&lt;/p&gt;</summary><category term="generalized Hyperbolic disribution"></category><category term="normal inverse Gaussian"></category><category term="Laplace distribution"></category><category term="convolution invariant"></category></entry><entry><title>LeaveOneOut</title><link href="/articles/2013/06/leaveoneout/" rel="alternate"></link><updated>2013-06-14T00:00:00+02:00</updated><author><name>Podgorski</name></author><id>tag:,2013-06-14:articles/2013/06/leaveoneout/</id><summary type="html">&lt;p&gt;In this article, we study an estimator of the location parameters ($\delta$) when the
density grows as $cx^{-1}$ when $x \rightarrow 0$. The idea is simply to remove the density ,$f(x_i-\delta)$, coming from observation $i=\argmin_j |x_j-\delta|$ from the log likelihood to get the LeaveOneOut&lt;/p&gt;
&lt;p&gt;$$
    L(\delta) = \sum_{j \neq i} \log(f(x_i-\delta)).
$$&lt;/p&gt;
&lt;h4&gt;Extensions:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The optimal rate of convergence it not achived. Is this due to 
the method is lacking, or due to the proof is lacking?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We study this class of densities manly beacuse that the &lt;a href="https://en.wikipedia.org/wiki/Variance-gamma_distribution"&gt;Generalized Laplace distribution&lt;/a&gt; (Variance Gamma) is contained in the class. It remains to show that consisteny for the LeaveOneOut likelihood for all the parameters of the distribution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="consistent estimator"></category><category term="unbounded density"></category><category term="article"></category><category term="Laplace distribution"></category></entry></feed>